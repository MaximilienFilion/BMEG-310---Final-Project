cat("\nTest Set Performance:\n")
cat("Accuracy:", sum(diag(test_conf_matrix_pca)) / sum(test_conf_matrix_pca),
"\nPrecision:", test_conf_matrix_pca[1,1] / (test_conf_matrix_pca[1,1] + test_conf_matrix_pca[1,2]),
"\nRecall:", test_conf_matrix_pca[1,1] / (test_conf_matrix_pca[1,1] + test_conf_matrix_pca[2,1]), "\n")
pred.prob <- predict(your.model, ovarian.dataset, type="response")
#install.packages("ROCR")
library(ROCR)
install.packages("ROCR")
#install.packages("ROCR")
library(ROCR)
#predicted probabilities from trained model
pred.prob <- predict(glm.fit, scaled_ovarian_dataset_test_and_diagnosis, type = "response")
View(glm.fit)
#install.packages("ROCR")
library(ROCR)
#predicted probabilities from trained model
pred.prob <- predict(glm.fit, test_pcs, type = "response")
#prediction object for ROCR
pred <- prediction(pred.prob, test_pcs$diagnosis, label.ordering = c("B", "M"))
#performance - true positive rate vs false positive rate)
perform <- performance(pred, "tpr", "fpr")
#plot ROC curve
plot(perform, colorize = TRUE, main = "ROC Curve for Logistic Regression Model")
abline(a = 0, b = 1, lty = 2, col = "grey")
#area under curve
auc <- performance(pred, measure = "auc")
auc_obj <- performance(pred, "auc")
auc_value <- unlist(slot(auc_obj, "y.values"))
cat("\nArea Under the Curve:", auc_value, "\n")
install.packages("rpart")
install.packages("rpart.plot")
#install.packages("rpart")
#install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
#fit decision tree
tree_model <- rpart(diagnosis ~ ., data = scaled_ovarian_dataset_train_and_diagnosis, method = "class")
#visualize
rpart.plot(tree_model, main = "Decision Tree for Diagnosis Classification")
#predictions
tree_pred_train <- predict(tree_model, scaled_ovarian_dataset_train_and_diagnosis, type = "class")
tree_pred_test <- predict(tree_model, scaled_ovarian_dataset_test_and_diagnosis, type = "class")
#train confusion matrix
train_conf_tree <- table(tree_pred_train, scaled_ovarian_dataset_train_and_diagnosis$diagnosis)
cat("\nTraining Performance:\n")
print(train_conf_tree)
cat("Accuracy:", sum(diag(train_conf_tree))/sum(train_conf_tree), "\n")
#test confusion matrix
test_conf_tree <- table(tree_pred_test, scaled_ovarian_dataset_test_and_diagnosis$diagnosis)
cat("\nTest Performance (Decision Tree):\n")
print(test_conf_tree)
cat("Accuracy:", sum(diag(test_conf_tree))/sum(test_conf_tree), "\n")
knitr::opts_chunk$set(echo = TRUE)
ovarian.dataset <- read.delim("ovarian.data", sep=",", header = FALSE)
features <- c("perimeter", "area", "smoothness", "symmetry", "concavity", paste("protein", seq(1, 25), sep=""))
names(ovarian.dataset) <- c("cell_id", "diagnosis", features)
head(ovarian.dataset)
summary(ovarian.dataset)
clean_ovarian_dataset <- na.omit(ovarian.dataset)
# Scale data to avoid skewing of the results due to sizing of the features
pca_data <- prcomp(clean_ovarian_dataset[, c(3:as.numeric(length(ovarian.dataset)))], center = TRUE, scale. = TRUE)
summary(pca_data)
cat("\nThe variance of the primary component is", summary(pca_data)$importance[2,1])
threshold <- 0.9
sum <- 0
total_PCs <- 0
for (i in 1:as.numeric(length(ovarian.dataset))){
sum <- sum + summary(pca_data)$importance[2,i]
total_PCs <- total_PCs + 1
if (sum >= threshold){
return(total_PCs)
}
}
cat("We need ", total_PCs, " principal components to explain 90% of the variance.")
# Extract PCA scores
pca_scores <- data.frame(pca_data$x[,1:2])
pca_scores$diagnosis <- clean_ovarian_dataset$diagnosis
# load the ggplot library
library(ggplot2)
ggplot(pca_scores, aes(x = PC1, y = PC2, color = diagnosis)) +
geom_point(alpha = 0.7, size = 2) +
labs(title = "PCA of Ovarian Dataset (First 2 Principal Components)",
x = "Principal Component 1",
y = "Principal Component 2") +
theme_minimal()
# Note that we used chatGPT for formatting and coloring.
# The prompt was: "what do you think of my last plot? is it correct? + code"
# The code that was submitted was the code from the tutorial:
# install.packages("devtools")
# library(devtools)
# install.packages("remotes")
# remotes::install_github("vqv/ggbiplot")
# library(ggbiplot)
# ggbiplot(mtcars.pca)
area_concavity_plot <- ggplot(clean_ovarian_dataset, aes(x = area, y = concavity, color = diagnosis)) +
geom_point(alpha = 0.8, size = 2) +
labs(title = "Area vs concavity",
x = "Area",
y = "Concavity") +
theme_minimal()
print(area_concavity_plot)
boxplot(pca_data$x,
main = "Distribution of Principal Components",
xlab = "Principal Components",
ylab = "Transformed Values",
outline = FALSE)
# Scale the data
clean_scaled_ovarian_dataset <- scale(clean_ovarian_dataset[c(3:ncol(clean_ovarian_dataset))], center = TRUE, scale = TRUE)
# K_mean clustering with 2 centers
k_mean_clean_ovarian_data <- kmeans(clean_scaled_ovarian_dataset, centers = 2)
# Extract the prediction vector from the clustering type
predictions_vector <- k_mean_clean_ovarian_data$cluster
# Create a vector of true labels
true_labels_vector <- clean_ovarian_dataset$diagnosis
# Case 1
# Convert the the cluster labels to diagnosis labels
predictions_vector_1 <- ifelse(predictions_vector == 1, "M", "B")
# Compare the model predictions to true labels
confusion_matrix_1 <- table(predictions_vector_1, true_labels_vector)
# Compute accuracy
accuracy_1 <- sum(diag(confusion_matrix_1)/sum(confusion_matrix_1))
# Case 2
# Convert the the cluster labels to diagnosis labels
predictions_vector_2 <- ifelse(predictions_vector == 2, "M", "B")
# Compare the model predictions to true labels
confusion_matrix_2 <- table(predictions_vector_2, true_labels_vector)
# Compute accuracy
accuracy_2 <- sum(diag(confusion_matrix_2)/sum(confusion_matrix_2))
# Report the confusion matrix, accuracy, precision, and recall of the model with the best accuracy
if (accuracy_1 > accuracy_2){
print(confusion_matrix_1)
cat("\nAccuracy:", accuracy_1,
"\nPrecision:", confusion_matrix_1[1,1] / (confusion_matrix_1[1,1] + confusion_matrix_1[1,2]),
"\nRecall:", confusion_matrix_1[1,1] / (confusion_matrix_1[1,1] + confusion_matrix_1[2,1]))
} else {
print(confusion_matrix_2)
cat("\nAccuracy:", accuracy_2,
"\nPrecision:", confusion_matrix_2[1,1] / (confusion_matrix_2[1,1] + confusion_matrix_2[1,2]),
"\nRecall:", confusion_matrix_2[1,1] / (confusion_matrix_2[1,1] + confusion_matrix_2[2,1]))
}
total_accuracy <- 0
for (i in 1:10){
# K_mean clustering with 2 centers
k_mean_clean_ovarian_data <- kmeans(clean_scaled_ovarian_dataset, centers = 2)
# Extract the prediction vector from the clustering type
predictions_vector <- k_mean_clean_ovarian_data$cluster
# Create a vector of true labels
true_labels_vector <- clean_ovarian_dataset$diagnosis
# Case 1
# Convert the the cluster labels to diagnosis labels
predictions_vector_1 <- ifelse(predictions_vector == 1, "M", "B")
# Compare the model predictions to true labels
confusion_matrix_1 <- table(predictions_vector_1, true_labels_vector)
# Compute accuracy
accuracy_1 <- sum(diag(confusion_matrix_1)/sum(confusion_matrix_1))
# Case 2
# Convert the the cluster labels to diagnosis labels
predictions_vector_2 <- ifelse(predictions_vector == 2, "M", "B")
# Compare the model predictions to true labels
confusion_matrix_2 <- table(predictions_vector_2, true_labels_vector)
# Compute accuracy
accuracy_2 <- sum(diag(confusion_matrix_2)/sum(confusion_matrix_2))
# Add the accuracy of the model to the total
if (accuracy_1 > accuracy_2){
total_accuracy <- total_accuracy + accuracy_1
} else {
total_accuracy <- total_accuracy + accuracy_2
}
}
Average_accuracy <- total_accuracy/10
cat("The average accuracy across 10 k_means model is: ", Average_accuracy)
total_accuracy <- 0
for (i in 1:10){
# K_mean clustering with 2 centers
k_mean_clean_pca_data <- kmeans(pca_data$x[,c(1:5)], centers = 2)
# Extract the prediction vector from the clustering type
predictions_vector <- k_mean_clean_pca_data$cluster
# Case 1
# Convert the the cluster labels to diagnosis labels
predictions_vector_1 <- ifelse(predictions_vector == 1, "M", "B")
# Compare the model predictions to true labels
confusion_matrix_1 <- table(predictions_vector_1, true_labels_vector)
# Compute accuracy
accuracy_1 <- sum(diag(confusion_matrix_1)/sum(confusion_matrix_1))
# Case 2
# Convert the the cluster labels to diagnosis labels
predictions_vector_2 <- ifelse(predictions_vector == 2, "M", "B")
# Compare the model predictions to true labels
confusion_matrix_2 <- table(predictions_vector_2, true_labels_vector)
# Compute accuracy
accuracy_2 <- sum(diag(confusion_matrix_2)/sum(confusion_matrix_2))
# Add the accuracy of the model to the total
if (accuracy_1 > accuracy_2){
total_accuracy <- total_accuracy + accuracy_1
} else {
total_accuracy <- total_accuracy + accuracy_2
}
}
Average_accuracy <- total_accuracy/10
cat("The average accuracy across 10 k_means model is: ", Average_accuracy)
ovarian.dataset.train <- ovarian.dataset[sample(nrow(ovarian.dataset))[1:(nrow(ovarian.dataset)/2)],]
ovarian.dataset.test <- ovarian.dataset[sample(nrow(ovarian.dataset))[(nrow(ovarian.dataset)/2):(nrow(ovarian.dataset))],]
# Load the ISLR library
library(ISLR)
# Data exploration
#install.packages("corrplot")
# Load the corrplot library
library(corrplot)
# scale the data
scaled_ovarian_dataset_train <- scale(ovarian.dataset.train[c(3:ncol(ovarian.dataset.train))], center = TRUE, scale = TRUE)
scaled_ovarian_dataset_test <- scale(ovarian.dataset.test[c(3:ncol(ovarian.dataset.train))], center = TRUE, scale = TRUE)
# Look for correlation between variables
correlations <- cor(scaled_ovarian_dataset_train[,1:30])
corrplot(correlations, method="circle")
# Prepare the data for fitting and testing
scaled_ovarian_dataset_train_and_diagnosis <- data.frame(
diagnosis = ovarian.dataset.train[, 2],
scaled_ovarian_dataset_train
)
scaled_ovarian_dataset_test_and_diagnosis <- data.frame(
diagnosis = ovarian.dataset.test[, 2],
scaled_ovarian_dataset_test
)
colnames(scaled_ovarian_dataset_train_and_diagnosis)[1] <- "diagnosis"
colnames(scaled_ovarian_dataset_test_and_diagnosis)[1] <- "diagnosis"
scaled_ovarian_dataset_train_and_diagnosis$diagnosis <- factor(
scaled_ovarian_dataset_train_and_diagnosis$diagnosis,
levels = c("B", "M")
)
scaled_ovarian_dataset_test_and_diagnosis$diagnosis <- factor(
scaled_ovarian_dataset_test_and_diagnosis$diagnosis,
levels = c("B", "M")
)
# Fit a logistic regression on the training set
glm.fit <- glm(diagnosis ~ perimeter + area + smoothness + symmetry + concavity + protein1 + protein2 + protein3 + protein4 + protein5 + protein6 + protein7 + protein8 + protein9 + protein10 + protein11 + protein12 + protein13 + protein14 + protein15 + protein16 + protein17 + protein18 + protein19 + protein20 + protein21 + protein22 + protein23 + protein24 + protein25, data = scaled_ovarian_dataset_train_and_diagnosis, family = binomial)
# summary(glm.fit)
# Report the accuracy on the train set
glm.probs.train <- predict(glm.fit, scaled_ovarian_dataset_train_and_diagnosis, type = "response")
glm.pred.train <- ifelse(glm.probs.train > 0.5, "M", "B")
glm.pred.train <- factor(glm.pred.train, levels = c("B", "M"))
train_conf_matrix <- table(glm.pred.train, scaled_ovarian_dataset_train_and_diagnosis$diagnosis)
print(train_conf_matrix)
cat("\nAccuracy:", sum(diag(train_conf_matrix)/sum(train_conf_matrix)),
"\nPrecision:", train_conf_matrix[1,1] / (train_conf_matrix[1,1] + train_conf_matrix[1,2]),
"\nRecall:", train_conf_matrix[1,1] / (train_conf_matrix[1,1] + train_conf_matrix[2,1]),
"\n")
# Report the accuracy on the test set
glm.probs.test <- predict(glm.fit, scaled_ovarian_dataset_test_and_diagnosis, type = "response")
glm.pred.test <- ifelse(glm.probs.test > 0.5, "M", "B")
glm.pred.test <- factor(glm.pred.test, levels = c("B", "M"))
test_conf_matrix <- table(glm.pred.test, scaled_ovarian_dataset_test_and_diagnosis$diagnosis)
print(test_conf_matrix)
cat("\nAccuracy:", sum(diag(test_conf_matrix))/sum(test_conf_matrix),
"\nPrecision:", test_conf_matrix[1,1] / (test_conf_matrix[1,1] + test_conf_matrix[1,2]),
"\nRecall:", test_conf_matrix[1,1] / (test_conf_matrix[1,1] + test_conf_matrix[2,1]))
train_pca <- prcomp(scaled_ovarian_dataset_train, center = TRUE, scale. = TRUE)
#top 5 only
train_pcs <- data.frame(train_pca$x[, 1:5])
test_pcs <- data.frame(predict(train_pca, newdata = scaled_ovarian_dataset_test)[, 1:5])
#combine pcs with diagnosis label
train_pcs$diagnosis <- ovarian.dataset.train$diagnosis
test_pcs$diagnosis <- ovarian.dataset.test$diagnosis
# Make the first column a factor and not a list of characters
train_pcs$diagnosis <- factor(
train_pcs$diagnosis,
levels = c("B", "M")
)
test_pcs$diagnosis <- factor(
test_pcs$diagnosis,
levels = c("B", "M")
)
#fit model
glm.fit <- glm(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5, data = train_pcs, family = binomial)
#training performace
glm.probs.train.pca <- predict(glm.fit, train_pcs, type = "response")
glm.pred.train.pca <- ifelse(glm.probs.train.pca > 0.5, "M", "B")
glm.pred.train.pca <- factor(glm.pred.train.pca, levels = c("B", "M"))
train_conf_matrix_pca <- table(glm.pred.train.pca, train_pcs$diagnosis)
print(train_conf_matrix_pca)
cat("\nTraining Set Performance:\n")
cat("Accuracy:", sum(diag(train_conf_matrix_pca)) / sum(train_conf_matrix_pca),
"\nPrecision:", train_conf_matrix_pca[1,1] / (train_conf_matrix_pca[1,1] + train_conf_matrix_pca[1,2]),
"\nRecall:", train_conf_matrix_pca[1,1] / (train_conf_matrix_pca[1,1] + train_conf_matrix_pca[2,1]), "\n")
#test performance
glm.probs.test.pca <- predict(glm.fit, test_pcs, type = "response")
glm.pred.test.pca <- ifelse(glm.probs.test.pca > 0.5, "M", "B")
glm.pred.test.pca <- factor(glm.pred.test.pca, levels = c("B", "M"))
test_conf_matrix_pca <- table(glm.pred.test.pca, test_pcs$diagnosis)
print(test_conf_matrix_pca)
cat("\nTest Set Performance:\n")
cat("Accuracy:", sum(diag(test_conf_matrix_pca)) / sum(test_conf_matrix_pca),
"\nPrecision:", test_conf_matrix_pca[1,1] / (test_conf_matrix_pca[1,1] + test_conf_matrix_pca[1,2]),
"\nRecall:", test_conf_matrix_pca[1,1] / (test_conf_matrix_pca[1,1] + test_conf_matrix_pca[2,1]), "\n")
#install.packages("ROCR")
library(ROCR)
#predicted probabilities from trained model
pred.prob <- predict(glm.fit, test_pcs, type = "response")
#prediction object for ROCR
pred <- prediction(pred.prob, test_pcs$diagnosis, label.ordering = c("B", "M"))
#performance - true positive rate vs false positive rate)
perform <- performance(pred, "tpr", "fpr")
#plot ROC curve
plot(perform, colorize = TRUE, main = "ROC Curve for Logistic Regression Model")
abline(a = 0, b = 1, lty = 2, col = "grey")
#area under curve
auc <- performance(pred, measure = "auc")
auc_obj <- performance(pred, "auc")
auc_value <- unlist(slot(auc_obj, "y.values"))
cat("\nArea Under the Curve:", auc_value, "\n")
#install.packages("rpart")
#install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
#fit decision tree
tree_model <- rpart(diagnosis ~ ., data = scaled_ovarian_dataset_train_and_diagnosis, method = "class")
#visualize
rpart.plot(tree_model, main = "Decision Tree for Diagnosis Classification")
#predictions
tree_pred_train <- predict(tree_model, scaled_ovarian_dataset_train_and_diagnosis, type = "class")
tree_pred_test <- predict(tree_model, scaled_ovarian_dataset_test_and_diagnosis, type = "class")
#train confusion matrix
train_conf_tree <- table(tree_pred_train, scaled_ovarian_dataset_train_and_diagnosis$diagnosis)
cat("\nTraining Performance:\n")
print(train_conf_tree)
cat("Accuracy:", sum(diag(train_conf_tree))/sum(train_conf_tree), "\n")
#test confusion matrix
test_conf_tree <- table(tree_pred_test, scaled_ovarian_dataset_test_and_diagnosis$diagnosis)
cat("\nTest Performance (Decision Tree):\n")
print(test_conf_tree)
cat("Accuracy:", sum(diag(test_conf_tree))/sum(test_conf_tree), "\n")
# This function performs the needleman-wunsch alignment on two DNA character strings. It will apply a penality of -2 for a gap, -1 for a base transition (C-T or A-G mutation), -5 for a transversion, and 1 for a match. the first argument is the reference and the second is the segment we try to align. It returns a matrix, representing the scores of different alignments.
needleman_wunsch <- function(s1, s2) {
# convert the DNA sequence to a numeric vector
s1 <- ifelse(s1 == "A", 1, ifelse(s1 == "T", 2, ifelse(s1 == "C", 3, ifelse(s1 == "G", 4, -1))))
s2 <- ifelse(s2 == "A", 1, ifelse(s2 == "T", 2, ifelse(s2 == "C", 3, ifelse(s2 == "G", 4, -1))))
# create a transition transversion matrix
penalty_matrix <- rbind(c(1,-5,-5,-1),c(-5,1,-1,-5),c(-5,-1,1,-5), c(-1,-5,-5,1))
# create gap penalty
gap_penalty <- -2
# Needleman-Wunsch algorithm
# Initiate the matrix
storing_table <- matrix(0, nrow = (length(s2) + 1), ncol = (length(s1) + 1))
# fill in with gap penalty on the x-axis
for (i in 2:ncol(storing_table)){
storing_table[1,i] <- (-2) * (i-1)
}
# fill in with gap penalty on the y-axis
for (i in 2:nrow(storing_table)){
storing_table[i,1] <- (-2) * (i-1)
}
# fill the table
for (i in 2:nrow(storing_table)){
for (j in 2:ncol(storing_table)){
match_score <- storing_table[i - 1, j - 1] + penalty_matrix[s2[i - 1], s1[j - 1]]
delete_score <- storing_table[i - 1, j] + gap_penalty
insert_score <- storing_table[i, j - 1] + gap_penalty
storing_table[i, j] <- max(match_score, delete_score, insert_score)
}
}
# Traceback of the Needleman-Wunsch Score Matrix
# initialize the number of steps that it will take to reach the first cell
i <- nrow(storing_table)
j <- ncol(storing_table)
traceback_vector <- c()
# convert the DNA sequence to a numeric vector
s1 <- ifelse(s1 == "A", 1, ifelse(s1 == "T", 2, ifelse(s1 == "C", 3, ifelse(s1 == "G", 4, -1))))
s2 <- ifelse(s2 == "A", 1, ifelse(s2 == "T", 2, ifelse(s2 == "C", 3, ifelse(s2 == "G", 4, -1))))
# create a transition transversion matrix
penalty_matrix <- rbind(c(1,-5,-5,-1),c(-5,1,-1,-5),c(-5,-1,1,-5), c(-1,-5,-5,1))
# create gap penalty
gap_penalty <- -2
while (i > 1 && j > 1) {
score <- storing_table[i, j]
diag_score <- storing_table[i - 1, j - 1] + penalty_matrix[s2[i - 1], s1[j - 1]]
up_score   <- storing_table[i - 1, j] + gap_penalty
left_score <- storing_table[i, j - 1] + gap_penalty
# check which direction produced the current score
if (score == diag_score) {
traceback_vector <- c(traceback_vector, "diag")
i <- i - 1
j <- j - 1
} else if (score == up_score) {
traceback_vector <- c(traceback_vector, "up")
i <- i - 1
} else if (score == left_score) {
traceback_vector <- c(traceback_vector, "left")
j <- j - 1
}
}
print(traceback_vector)
}
# Create the two DNA sequence objects
seq1 <- strsplit("ATTCGAC", split = "")[[1]]
seq2 <- strsplit("ATCAC", split = "")[[1]]
# Call the function on those two sequences
needleman_wunsch(seq1, seq2)
# This function performs the needleman-wunsch alignment on two DNA character strings. It will apply a penality of -2 for a gap, -1 for a base transition (C-T or A-G mutation), -5 for a transversion, and 1 for a match. the first argument is the reference and the second is the segment we try to align. It returns a matrix, representing the scores of different alignments.
needleman_wunsch <- function(s1, s2) {
# convert the DNA sequence to a numeric vector
s1 <- ifelse(s1 == "A", 1, ifelse(s1 == "T", 2, ifelse(s1 == "C", 3, ifelse(s1 == "G", 4, -1))))
s2 <- ifelse(s2 == "A", 1, ifelse(s2 == "T", 2, ifelse(s2 == "C", 3, ifelse(s2 == "G", 4, -1))))
# create a transition transversion matrix
penalty_matrix <- rbind(c(1,-5,-5,-1),c(-5,1,-1,-5),c(-5,-1,1,-5), c(-1,-5,-5,1))
# create gap penalty
gap_penalty <- -2
# Needleman-Wunsch algorithm
# Initiate the matrix
storing_table <- matrix(0, nrow = (length(s2) + 1), ncol = (length(s1) + 1))
# fill in with gap penalty on the x-axis
for (i in 2:ncol(storing_table)){
storing_table[1,i] <- (-2) * (i-1)
}
# fill in with gap penalty on the y-axis
for (i in 2:nrow(storing_table)){
storing_table[i,1] <- (-2) * (i-1)
}
# fill the table
for (i in 2:nrow(storing_table)){
for (j in 2:ncol(storing_table)){
match_score <- storing_table[i - 1, j - 1] + penalty_matrix[s2[i - 1], s1[j - 1]]
delete_score <- storing_table[i - 1, j] + gap_penalty
insert_score <- storing_table[i, j - 1] + gap_penalty
storing_table[i, j] <- max(match_score, delete_score, insert_score)
}
}
# Traceback of the Needleman-Wunsch Score Matrix
# initialize the number of steps that it will take to reach the first cell
i <- nrow(storing_table)
j <- ncol(storing_table)
traceback_vector <- c()
# create a transition transversion matrix
penalty_matrix <- rbind(c(1,-5,-5,-1),c(-5,1,-1,-5),c(-5,-1,1,-5), c(-1,-5,-5,1))
while (i > 1 && j > 1) {
score <- storing_table[i, j]
diag_score <- storing_table[i - 1, j - 1] + penalty_matrix[s2[i - 1], s1[j - 1]]
up_score   <- storing_table[i - 1, j] + gap_penalty
left_score <- storing_table[i, j - 1] + gap_penalty
# check which direction produced the current score
if (score == diag_score) {
traceback_vector <- c(traceback_vector, "diag")
i <- i - 1
j <- j - 1
} else if (score == up_score) {
traceback_vector <- c(traceback_vector, "up")
i <- i - 1
} else if (score == left_score) {
traceback_vector <- c(traceback_vector, "left")
j <- j - 1
}
}
print(traceback_vector)
}
# Create the two DNA sequence objects
seq1 <- strsplit("ATTCGAC", split = "")[[1]]
seq2 <- strsplit("ATCAC", split = "")[[1]]
# Call the function on those two sequences
needleman_wunsch(seq1, seq2)
setwd("C:/Users/maxim/Desktop/BMEG 310/BMEG-310---Final-Project")
knitr::opts_chunk$set(echo = TRUE)
RNAseq_KIRC <- read.csv("RNAseq_KIRC.csv")
data_clinical_patient <- read.delim("data_clinical_patient.txt", header = TRUE, sep = "\t", skip = 4)
data_mutations <- read.delim("data_mutations.txt", header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# RNAseq_KIRC dataset
rna_patient_ids <- gsub("\\.", "-", substr(colnames(RNAseq_KIRC), 1, 12))
RNAseq_KIRC_num_patients <- length(unique(rna_patient_ids))
cat("Number of unique patients in the RNAseq_KIRC dataset:", RNAseq_KIRC_num_patients, "\n")
# Data_clinical_patient dataset
clinical_patient_ids <- unique(data_clinical_patient$PATIENT_ID)
data_clinical_patient_num_patients <- length(clinical_patient_ids)
cat("Number of unique patients in the clinical dataset:", data_clinical_patient_num_patients, "\n")
# Data_mutation dataset
mutation_patient_ids <- unique(substr(data_mutations$Tumor_Sample_Barcode, 1, 12))
data_mutations_num_patients <- length(mutation_patient_ids)
cat("Number of unique patients in the mutation dataset:", data_mutations_num_patients, "\n")
common_patients <- Reduce(intersect, list(rna_patient_ids, clinical_patient_ids, mutation_patient_ids))
cat("Number of patients with all three data types:", length(common_patients), "\n")
View(data_clinical_patient)
BiocManager::install("DESeq2")
BiocManager::install("DESeq2")
install.packages("pheatmap")
install.packages("ggplot2")
BiocManager::install("AnnotationDbi")
BiocManager::install("org.Hs.eg.db")
BiocManager::install("pathview")
BiocManager::install("gage")
BiocManager::install("gageData")
RNAseq_KIRC <- read.csv("RNAseq_KIRC.csv")
data_clinical_patient <- read.delim("data_clinical_patient.txt", header = TRUE, sep = "\t", skip = 4)
data_mutations <- read.delim("data_mutations.txt", header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# RNAseq_KIRC dataset
rna_patient_ids <- gsub("\\.", "-", substr(colnames(RNAseq_KIRC), 1, 12))
# Data_clinical_patient dataset
clinical_patient_ids <- unique(data_clinical_patient$PATIENT_ID)
# Data_mutation dataset
mutation_patient_ids <- unique(substr(data_mutations$Tumor_Sample_Barcode, 1, 12))
# Common patients
common_patients <- Reduce(intersect, list(rna_patient_ids, clinical_patient_ids, mutation_patient_ids))
# Age associated with patients
common_patient_ages <- data_clinical_patient$AGE[match(common_patients, data_clinical_patient$PATIENT_ID)]
# Load the ggplot2 library
library(ggplot2)
# Convert to a dataframe
age_df <- data.frame(AGE = common_patient_ages)
# Plot the boxplot
ggplot(age_df, aes(x = AGE)) +
geom_boxplot(fill = "skyblue", color = "black") +
labs(
title = "Distribution of Ages Among Patients",
x = "Age (years)",
y = ""
) +
theme_minimal(base_size = 14)
